---
layout: about
title: About
permalink: /
subtitle: 

profile:
  align: right
  image: head_shot.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <p>firstlast@berkeley.edu</p>

news: false # includes a list of news items
selected_papers: false # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

I am a Member of Technical Staff at xAI, working on reasoning, post-training, and RL.
- [Grok 4 Fast](https://x.ai/news/grok-4-fast): Co-creator, lead post-training RL training and recipe studies, co-lead distillation and evals.
- [Grok 4](https://x.ai/news/grok-4): Core contributor, synthetic datasets, evals, tool use.

Previously, I was an EECS undergraduate at UC Berkeley, where I was fortunated to be advised by [Ion Stoica](https://people.eecs.berkeley.edu/~istoica/) and built [LMArena](https://lmarena.ai/). During my undergrad, I also spent a year full-time at Nexusflow as part of the LLM post-training team, collaborating with [Banghua Zhu](https://people.eecs.berkeley.edu/~banghua/) and [Jiantao Jiao](https://people.eecs.berkeley.edu/~jiantao/). Additionally, I briefly worked as a student researcher at Google AI Research, on reasoning.

I am very interested in fundamental problems in training large models, building more capable and reliable models, and solving superintelligence. Some of the concrete problems I have been thinking about recently:
1. How can we transfer intelligence learned in verifiable domains to open-ended questions?
2. Design and formulate less hackable and more interpretable reward signals for presentation and style.
3. How can we leverage multi-agents to train smarter models.
4. How to train faster, more reasoning efficient models via large scale RL?
