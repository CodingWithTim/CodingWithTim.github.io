---
layout: about
title: About
permalink: /
subtitle: 

profile:
  align: right
  image: head_shot.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <strong><center>Li, Tianle (李天乐)<center></strong>
    <p>My name literally means "be happy everyday" in Chinese.</p>

news: false # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---
**Email**: firstlast@berkeley.edu \\
**[Linkedin](https://www.linkedin.com/in/tianleli/)** / **[Google Scholar](https://scholar.google.com/citations?hl=en&user=1M79iLwAAAAJ)** / **[X](https://x.com/LiTianleli)**

I am an undergraduate researcher at [Berkeley Sky Computing Lab](https://sky.cs.berkeley.edu/) and a member of Large Model Systems Organization ([LMSys](https://lmsys.org/)), advised by Professor [Ion Stoica](https://people.eecs.berkeley.edu/~istoica/) and Professor [Joseph E. Gonzalez](https://people.eecs.berkeley.edu/~jegonzal/), where I focus on building [Chatbot Arena](https://chat.lmsys.org/) and working on various aspects of Large Language Models (LLMs) Evaluation. 

I am also a Research Engineer on the LLM post-training team at [Nexusflow](https://nexusflow.ai/), working with Professor [Jiantao Jiao](https://people.eecs.berkeley.edu/~jiantao/).

I recently started working on reasoning models as a Student Researcher at Google.

### Education
I am currently a senior at UC Berkeley studying Electrical Engineering and Computer Science (EECS).

### Research

My research interest lies in the intersection of **Large Model Evaluation** and **Post-Training** with a focus on understanding and improving Large Model's general and domain-specific capabilities and reliability. I am super curious about principled approaches to identifying limitations in LLMs and leveraging these insights to overcome them through innovative training methods or data curation.

Some of my work:
- **LLM evaluations**
  - Crowdsource Evaluation: [Chatbot Arena](https://chat.lmsys.org/) (Core Contributor)
      - Infra and Data Analytics.
      - I built the categories: Hard Prompt, Style Control, Math, etc.
      - PDFChat, Search Arena, User Leaderboard.
  - Automatic Benchmark: [Arena-Hard-Auto](https://github.com/lmarena/arena-hard-auto/tree/main) (Lead)
  - Reward Model Benchmark: [Preference Proxy Evaluator](https://github.com/lmarena/PPE) (Core Contributor)
  - Prompt-to-Leaderboard: [P2L](https://arxiv.org/pdf/2502.14855) (Co-first Author)
- **Post-training and datasets**
  - Open Model Trained: [Athene-70B](https://huggingface.co/Nexusflow/Athene-70B) (Co-Lead), [Athene-V2-Chat-72B](https://huggingface.co/Nexusflow/Athene-V2-Chat) (Co-Lead)
  - Open Dataset: [LMSYS-Chat-1M](https://huggingface.co/datasets/lmsys/lmsys-chat-1m) (Core Contributor)
- **Systems for training and serving large models**
  - [FastChat](https://github.com/lm-sys/FastChat) (Contributor)

### Teaching / Other Experiences

- EECS127 (Convex Optimization): Teaching Assistant, 2023-2024
- AMD: Software Engineer Intern, 2023
